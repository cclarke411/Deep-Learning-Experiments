{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "parameteroptimization1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cclarke411/Deep-Learning-Experiments/blob/master/parameteroptimization1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7CxtsZVzy8D",
        "colab_type": "code",
        "outputId": "7a26bc68-d97e-48af-e6a8-93d1fd6aa446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "\n",
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "from keras.datasets import mnist\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.utils  import to_categorical\n",
        "from keras import losses, models, optimizers\n",
        "from keras.layers import  Dense,Conv2D,Flatten,MaxPooling2D,Dropout,Activation,GaussianNoise,BatchNormalization,LeakyReLU,AveragePooling2D\n",
        "from keras import regularizers, optimizers\n",
        "from keras.activations import relu, softmax\n",
        "from keras.layers import Input,GlobalMaxPool1D,MaxPool1D\n",
        "from keras.layers import Convolution1D\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biCNhyQqydvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install hyperas\n",
        "!pip install hyperopt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FokHe0D48zh",
        "colab_type": "code",
        "outputId": "3f63baa1-0cc2-4571-c802-06a281edb9e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbBcGcv5zJ2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# See: https://stackoverflow.com/questions/49920031/get-the-path-of-the-notebook-on-google-colab\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Copy/download the file\n",
        "fid = drive.ListFile({'q':\"title='parameteroptimization1.ipynb'\"}).GetList()[0]['id']\n",
        "f = drive.CreateFile({'id': fid})\n",
        "f.GetContentFile('parameteroptimization1.ipynb')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlcBtDmn1AB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_path = '/content/drive/My Drive/Speech1'\n",
        "os.chdir(save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJPhoAUv5kJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NM_test   = np.load('NM_test.npy')\n",
        "NM_train  = np.load('NM_train.npy')\n",
        "NMy_test1 = np.load('NMy_test1.npy')\n",
        "NMy_train1= np.load('NMy_train1.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hciOKfPhLFO6",
        "colab_type": "code",
        "outputId": "0b459677-a770-4abc-8804-67c79fc695d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "NM_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5450, 128, 87, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niNofgjJLAHq",
        "colab_type": "code",
        "outputId": "1f226db6-cb50-47e5-b857-99a43a617903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from shutil import copyfile\n",
        "copyfile('/content/drive/My Drive/Speech1/NM_test.npy', '/content/NM_test.npy')\n",
        "copyfile('/content/drive/My Drive/Speech1/NM_train.npy', '/content/NM_train.npy')\n",
        "copyfile('/content/drive/My Drive/Speech1/NMy_test1.npy', '/content/NMy_test1.npy')\n",
        "copyfile('/content/drive/My Drive/Speech1/NMy_train1.npy', '/content/NMy_train1.npy')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/NMy_train1.npy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWcbYbdNWKPO",
        "colab_type": "code",
        "outputId": "50db485c-e317-4c61-9a64-36d3fbd0fcf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "copyfile('/content/drive/My Drive/Speech1/y_mfccs,target.npy','/content/y_data.npy')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/y_data.npy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_s0VD4WXkCQ",
        "colab_type": "code",
        "outputId": "7840417d-c466-489a-962f-5c3552f47852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "copyfile('/content/drive/My Drive/Speech1/y_mfccs_labels.npy','/content/yp.npy')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/yp.npy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwbURHXM6Jr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_data = np.load('y_data.npy')\n",
        "yp = np.load('yp.npy')\n",
        "\n",
        "data_1D = np.expand_dims(y_data,axis = 2).reshape(13623,44100,1)\n",
        "NewX1D_train, NewX1D_test, Newy1D_train, Newy1D_test = train_test_split(data_1D, to_categorical(yp), test_size=0.5, shuffle = True)\n",
        "X_train = NewX1D_train\n",
        "Y_train = Newy1D_train\n",
        "X_test = NewX1D_test\n",
        "Y_test = Newy1D_test\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhr855QlaT6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('NewX1D_train.npy',NewX1D_train)\n",
        "np.save('NewX1D_test.npy',NewX1D_test)\n",
        "np.save('Newy1D_train.npy',Newy1D_train)\n",
        "np.save('Newy1D_test.npy',Newy1D_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXWClVPjc5QP",
        "colab_type": "code",
        "outputId": "1e80ca56-4f74-408a-f3e7-17370bb2d0a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6811, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXDGYu2eyk6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_1d():\n",
        "  X_train = np.load('NewX1D_train.npy')\n",
        "  Y_train = np.load('Newy1D_train.npy')\n",
        "  X_test = np.load('NewX1D_test.npy')\n",
        "  Y_test = np.load('Newy1D_train.npy')\n",
        "  X_test = X_test[0:6811]\n",
        "  Y_test = Y_test[0:6811]\n",
        "  return X_train, Y_train, X_test, Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYX-ylT87XpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_1d_model(X_train, Y_train, X_test, Y_test):\n",
        "    nclass=30\n",
        "    model = Sequential()\n",
        "    model.add(Convolution1D(1,16, activation=relu, padding=\"valid\",input_shape=(44100,1)))\n",
        "    model.add(Convolution1D(1,16, activation=relu, padding=\"valid\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool1D(16))\n",
        "    model.add(Dropout({{uniform(0, 1)}}))\n",
        "    \n",
        "    model.add(Convolution1D(1,32, activation=relu, padding=\"valid\"))\n",
        "    model.add(Convolution1D(1,32, activation=relu, padding=\"valid\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool1D(4))\n",
        "    model.add(Dropout({{uniform(0, 1)}}))\n",
        "    \n",
        "    model.add(Convolution1D(1,32, activation=relu, padding=\"valid\"))\n",
        "    model.add(Convolution1D(1,32, activation=relu, padding=\"valid\"))\n",
        "    model.add(MaxPool1D(4))\n",
        "    model.add(Dropout(rate=0.1))\n",
        "    \n",
        "    model.add(Convolution1D(1,32, activation=relu, padding=\"valid\"))\n",
        "    model.add(Convolution1D(1,32, activation=relu, padding=\"valid\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(GlobalMaxPool1D())\n",
        "    model.add(Dropout({{uniform(0, 1)}}))\n",
        "\n",
        "    model.add(Dense({{choice([64, 128, 256])}}, activation=relu))\n",
        "    model.add(Dense({{choice([64, 128, 256])}}, activation=relu))\n",
        "    model.add(Dense(nclass, activation=softmax))\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}},\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size={{choice([64, 128])}},\n",
        "              nb_epoch=10,\n",
        "              verbose=2,\n",
        "              validation_data=(X_test, Y_test))\n",
        "    score, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "    print('Test accuracy:', acc)\n",
        "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-F9BHpcLM6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_2d():\n",
        "  X_train = np.load('NM_train.npy')\n",
        "  Y_train = np.load('NMy_train1.npy')\n",
        "  X_test = np.load('NM_test.npy')\n",
        "  Y_test = np.load('NMy_test1.npy')\n",
        "  X_test = X_test[0:5450]\n",
        "  Y_test = Y_test[0:5450]\n",
        "  return X_train, Y_train, X_test, Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shcq8LQeyvLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_2d_model(X_train, Y_train, X_test, Y_test):\n",
        "\n",
        "    model = Sequential()\n",
        "    #add model layers\n",
        "    model.add(Conv2D({{choice([64, 128, 256])}}, kernel_size={{choice([2, 3, 5])}}, activation='relu', input_shape=(128 ,87,1)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D({{choice([32, 64, 128])}}, kernel_size=3, activation= 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D({{choice([16, 32, 64])}}, kernel_size=3, activation= 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(30, activation='softmax'))\n",
        "\n",
        "    #compile model using accuracy to measure model performance\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}},\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size={{choice([64, 128])}},\n",
        "              nb_epoch=10,\n",
        "              verbose=2,\n",
        "              validation_data=(X_test, Y_test))\n",
        "    score, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "    print('Test accuracy:', acc)\n",
        "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D7xW8Ozznp_",
        "colab_type": "code",
        "outputId": "87f5930f-b556-47f4-fd1c-92c62fc39623",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "best_run, best_model = optim.minimize(model=conv_1d_model,\n",
        "                                          data=data_1d,\n",
        "                                          max_evals=10,\n",
        "                                          algo=tpe.suggest,\n",
        "                                          notebook_name='parameteroptimization1', # This is important!\n",
        "                                          trials=Trials())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Imports:\n",
            "#coding=utf-8\n",
            "\n",
            "from __future__ import print_function\n",
            "\n",
            "try:\n",
            "    import numpy as np\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperopt import Trials, STATUS_OK, tpe\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.datasets import mnist\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers.core import Dense, Dropout, Activation\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.models import Sequential\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.utils import np_utils\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.models import Sequential\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.utils import to_categorical\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras import losses, models, optimizers\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, Activation, GaussianNoise, BatchNormalization, LeakyReLU, AveragePooling2D\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras import regularizers, optimizers\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.activations import relu, softmax\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Input, GlobalMaxPool1D, MaxPool1D\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Convolution1D\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas import optim\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas.distributions import choice, uniform\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import os\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.model_selection import train_test_split\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import drive\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from pydrive.auth import GoogleAuth\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from pydrive.drive import GoogleDrive\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import auth\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from oauth2client.client import GoogleCredentials\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from shutil import copyfile\n",
            "except:\n",
            "    pass\n",
            "\n",
            ">>> Hyperas search space:\n",
            "\n",
            "def get_space():\n",
            "    return {\n",
            "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
            "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
            "        'Dropout_2': hp.uniform('Dropout_2', 0, 1),\n",
            "        'Dense': hp.choice('Dense', [64, 128, 256]),\n",
            "        'Dense_1': hp.choice('Dense_1', [64, 128, 256]),\n",
            "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n",
            "        'batch_size': hp.choice('batch_size', [64, 128]),\n",
            "    }\n",
            "\n",
            ">>> Data\n",
            "  1: \n",
            "  2: X_train = np.load('NewX1D_train.npy')\n",
            "  3: Y_train = np.load('Newy1D_train.npy')\n",
            "  4: X_test = np.load('NewX1D_test.npy')\n",
            "  5: Y_test = np.load('Newy1D_train.npy')\n",
            "  6: X_test = X_test[0:6811]\n",
            "  7: Y_test = Y_test[0:6811]\n",
            "  8: \n",
            "  9: \n",
            " 10: \n",
            ">>> Resulting replaced keras model:\n",
            "\n",
            "   1: def keras_fmin_fnct(space):\n",
            "   2: \n",
            "   3:     nclass=30\n",
            "   4:     model = Sequential()\n",
            "   5:     model.add(Convolution1D(1,16, activation=relu, padding=\"valid\",input_shape=(44100,1)))\n",
            "   6:     model.add(Convolution1D(1,16, activation=relu, padding=\"valid\"))\n",
            "   7:     model.add(BatchNormalization())\n",
            "   8:     model.add(MaxPool1D(16))\n",
            "   9:     model.add(Dropout(space['Dropout']))\n",
            "  10:     \n",
            "  11:     model.add(Convolution1D(1,32, activation=relu, padding=\"valid\"))\n",
            "  12:     model.add(Convolution1D(1,32, activation=relu, padding=\"valid\"))\n",
            "  13:     model.add(BatchNormalization())\n",
            "  14:     model.add(MaxPool1D(4))\n",
            "  15:     model.add(Dropout(space['Dropout_1']))\n",
            "  16:     \n",
            "  17:     model.add(Convolution1D(1,32, activation=relu, padding=\"valid\"))\n",
            "  18:     model.add(Convolution1D(1,32, activation=relu, padding=\"valid\"))\n",
            "  19:     model.add(MaxPool1D(4))\n",
            "  20:     model.add(Dropout(rate=0.1))\n",
            "  21:     \n",
            "  22:     model.add(Convolution1D(1,32, activation=relu, padding=\"valid\"))\n",
            "  23:     model.add(Convolution1D(1,32, activation=relu, padding=\"valid\"))\n",
            "  24:     model.add(BatchNormalization())\n",
            "  25:     model.add(GlobalMaxPool1D())\n",
            "  26:     model.add(Dropout(space['Dropout_2']))\n",
            "  27: \n",
            "  28:     model.add(Dense(space['Dense'], activation=relu))\n",
            "  29:     model.add(Dense(space['Dense_1'], activation=relu))\n",
            "  30:     model.add(Dense(nclass, activation=softmax))\n",
            "  31:     \n",
            "  32:     model.compile(loss='binary_crossentropy',\n",
            "  33:                   optimizer=space['optimizer'],\n",
            "  34:                   metrics=['accuracy'])\n",
            "  35: \n",
            "  36:     model.fit(X_train, Y_train,\n",
            "  37:               batch_size=space['batch_size'],\n",
            "  38:               nb_epoch=10,\n",
            "  39:               verbose=2,\n",
            "  40:               validation_data=(X_test, Y_test))\n",
            "  41:     score, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
            "  42:     print('Test accuracy:', acc)\n",
            "  43:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
            "  44: \n",
            "  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:Large dropout rate: 0.610876 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.73717 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.651797 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/temp_model.py:173: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 6811 samples, validate on 6811 samples\n",
            "Epoch 1/10\n",
            " - 15s - loss: 0.1477 - acc: 0.9666 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 2/10\n",
            " - 7s - loss: 0.1473 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 3/10\n",
            " - 6s - loss: 0.1476 - acc: 0.9666 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 4/10\n",
            " - 7s - loss: 0.1474 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 5/10\n",
            " - 7s - loss: 0.1474 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 6/10\n",
            " - 7s - loss: 0.1470 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 7/10\n",
            " - 7s - loss: 0.1469 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 8/10\n",
            " - 7s - loss: 0.1470 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 9/10\n",
            " - 7s - loss: 0.1470 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 10/10\n",
            " - 7s - loss: 0.1468 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Test accuracy:\n",
            "0.9666666388511658\n",
            " 10%|█         | 1/10 [01:17<11:37, 77.53s/it, best loss: -0.9666666388511658]WARNING:tensorflow:Large dropout rate: 0.977001 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "WARNING:tensorflow:Large dropout rate: 0.836667 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/temp_model.py:173: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 6811 samples, validate on 6811 samples\n",
            "Epoch 1/10\n",
            " - 9s - loss: 0.1487 - acc: 0.9665 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 2/10\n",
            " - 7s - loss: 0.1472 - acc: 0.9666 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 3/10\n",
            " - 7s - loss: 0.1466 - acc: 0.9666 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 4/10\n",
            " - 7s - loss: 0.1464 - acc: 0.9666 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 5/10\n",
            " - 7s - loss: 0.1463 - acc: 0.9666 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 6/10\n",
            " - 7s - loss: 0.1462 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 7/10\n",
            " - 7s - loss: 0.1462 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 8/10\n",
            " - 7s - loss: 0.1461 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 9/10\n",
            " - 7s - loss: 0.1461 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 10/10\n",
            " - 7s - loss: 0.1461 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Test accuracy:\n",
            "0.9666666388511658\n",
            " 20%|██        | 2/10 [02:35<10:20, 77.61s/it, best loss: -0.9666666388511658]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/temp_model.py:173: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 6811 samples, validate on 6811 samples\n",
            "Epoch 1/10\n",
            " - 10s - loss: 0.1464 - acc: 0.9667 - val_loss: 0.1462 - val_acc: 0.9667\n",
            "\n",
            "Epoch 2/10\n",
            " - 7s - loss: 0.1461 - acc: 0.9667 - val_loss: 0.1462 - val_acc: 0.9667\n",
            "\n",
            "Epoch 3/10\n",
            " - 7s - loss: 0.1460 - acc: 0.9667 - val_loss: 0.1462 - val_acc: 0.9667\n",
            "\n",
            "Epoch 4/10\n",
            " - 7s - loss: 0.1457 - acc: 0.9667 - val_loss: 0.1463 - val_acc: 0.9667\n",
            "\n",
            "Epoch 5/10\n",
            " - 7s - loss: 0.1455 - acc: 0.9667 - val_loss: 0.1464 - val_acc: 0.9667\n",
            "\n",
            "Epoch 6/10\n",
            " - 7s - loss: 0.1453 - acc: 0.9667 - val_loss: 0.1466 - val_acc: 0.9667\n",
            "\n",
            "Epoch 7/10\n",
            " - 7s - loss: 0.1452 - acc: 0.9667 - val_loss: 0.1468 - val_acc: 0.9667\n",
            "\n",
            "Epoch 8/10\n",
            " - 7s - loss: 0.1452 - acc: 0.9667 - val_loss: 0.1469 - val_acc: 0.9667\n",
            "\n",
            "Epoch 9/10\n",
            " - 7s - loss: 0.1448 - acc: 0.9667 - val_loss: 0.1466 - val_acc: 0.9667\n",
            "\n",
            "Epoch 10/10\n",
            " - 7s - loss: 0.1444 - acc: 0.9667 - val_loss: 0.1473 - val_acc: 0.9667\n",
            "\n",
            "Test accuracy:\n",
            "0.9666666388511658\n",
            " 30%|███       | 3/10 [03:55<09:09, 78.52s/it, best loss: -0.9666666388511658]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/temp_model.py:173: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 6811 samples, validate on 6811 samples\n",
            "Epoch 1/10\n",
            " - 10s - loss: 0.1469 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 2/10\n",
            " - 7s - loss: 0.1460 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 3/10\n",
            " - 7s - loss: 0.1460 - acc: 0.9667 - val_loss: 0.1462 - val_acc: 0.9667\n",
            "\n",
            "Epoch 4/10\n",
            " - 7s - loss: 0.1459 - acc: 0.9667 - val_loss: 0.1462 - val_acc: 0.9667\n",
            "\n",
            "Epoch 5/10\n",
            " - 7s - loss: 0.1458 - acc: 0.9667 - val_loss: 0.1462 - val_acc: 0.9667\n",
            "\n",
            "Epoch 6/10\n",
            " - 7s - loss: 0.1457 - acc: 0.9667 - val_loss: 0.1462 - val_acc: 0.9667\n",
            "\n",
            "Epoch 7/10\n",
            " - 7s - loss: 0.1456 - acc: 0.9667 - val_loss: 0.1462 - val_acc: 0.9667\n",
            "\n",
            "Epoch 8/10\n",
            " - 7s - loss: 0.1456 - acc: 0.9667 - val_loss: 0.1462 - val_acc: 0.9667\n",
            "\n",
            "Epoch 9/10\n",
            " - 7s - loss: 0.1455 - acc: 0.9667 - val_loss: 0.1463 - val_acc: 0.9667\n",
            "\n",
            "Epoch 10/10\n",
            " - 7s - loss: 0.1455 - acc: 0.9667 - val_loss: 0.1463 - val_acc: 0.9667\n",
            "\n",
            "Test accuracy:\n",
            "0.9666666388511658\n",
            " 40%|████      | 4/10 [05:11<07:45, 77.63s/it, best loss: -0.9666666388511658]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/temp_model.py:173: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 6811 samples, validate on 6811 samples\n",
            "Epoch 1/10\n",
            " - 10s - loss: 0.1462 - acc: 0.9667 - val_loss: 0.1464 - val_acc: 0.9667\n",
            "\n",
            "Epoch 2/10\n",
            " - 7s - loss: 0.1459 - acc: 0.9667 - val_loss: 0.1462 - val_acc: 0.9667\n",
            "\n",
            "Epoch 3/10\n",
            " - 7s - loss: 0.1459 - acc: 0.9667 - val_loss: 0.1463 - val_acc: 0.9667\n",
            "\n",
            "Epoch 4/10\n",
            " - 7s - loss: 0.1457 - acc: 0.9667 - val_loss: 0.1467 - val_acc: 0.9667\n",
            "\n",
            "Epoch 5/10\n",
            " - 7s - loss: 0.1456 - acc: 0.9667 - val_loss: 0.1471 - val_acc: 0.9667\n",
            "\n",
            "Epoch 6/10\n",
            " - 7s - loss: 0.1458 - acc: 0.9667 - val_loss: 0.1462 - val_acc: 0.9667\n",
            "\n",
            "Epoch 7/10\n",
            " - 7s - loss: 0.1459 - acc: 0.9667 - val_loss: 0.1465 - val_acc: 0.9667\n",
            "\n",
            "Epoch 8/10\n",
            " - 7s - loss: 0.1456 - acc: 0.9667 - val_loss: 0.1465 - val_acc: 0.9667\n",
            "\n",
            "Epoch 9/10\n",
            " - 7s - loss: 0.1456 - acc: 0.9667 - val_loss: 0.1467 - val_acc: 0.9667\n",
            "\n",
            "Epoch 10/10\n",
            " - 7s - loss: 0.1454 - acc: 0.9667 - val_loss: 0.1472 - val_acc: 0.9667\n",
            "\n",
            "Test accuracy:\n",
            "0.966661744601855\n",
            " 50%|█████     | 5/10 [06:26<06:24, 76.83s/it, best loss: -0.9666666388511658]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/temp_model.py:173: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 6811 samples, validate on 6811 samples\n",
            "Epoch 1/10\n",
            " - 10s - loss: 0.1463 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 2/10\n",
            " - 7s - loss: 0.1461 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 3/10\n",
            " - 7s - loss: 0.1461 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 4/10\n",
            " - 7s - loss: 0.1461 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 5/10\n",
            " - 7s - loss: 0.1462 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 6/10\n",
            " - 7s - loss: 0.1461 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 7/10\n",
            " - 7s - loss: 0.1462 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 8/10\n",
            " - 7s - loss: 0.1462 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 9/10\n",
            " - 7s - loss: 0.1462 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 10/10\n",
            " - 7s - loss: 0.1461 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Test accuracy:\n",
            "0.9666666388511658\n",
            " 60%|██████    | 6/10 [07:40<05:03, 75.89s/it, best loss: -0.9666666388511658]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/temp_model.py:173: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 6811 samples, validate on 6811 samples\n",
            "Epoch 1/10\n",
            " - 10s - loss: 0.1457 - acc: 0.9667 - val_loss: 0.1462 - val_acc: 0.9667\n",
            "\n",
            "Epoch 2/10\n",
            " - 7s - loss: 0.1449 - acc: 0.9666 - val_loss: 0.1466 - val_acc: 0.9667\n",
            "\n",
            "Epoch 3/10\n",
            " - 7s - loss: 0.1442 - acc: 0.9667 - val_loss: 0.1467 - val_acc: 0.9667\n",
            "\n",
            "Epoch 4/10\n",
            " - 7s - loss: 0.1438 - acc: 0.9666 - val_loss: 0.1473 - val_acc: 0.9667\n",
            "\n",
            "Epoch 5/10\n",
            " - 7s - loss: 0.1435 - acc: 0.9666 - val_loss: 0.1477 - val_acc: 0.9667\n",
            "\n",
            "Epoch 6/10\n",
            " - 7s - loss: 0.1431 - acc: 0.9666 - val_loss: 0.1482 - val_acc: 0.9667\n",
            "\n",
            "Epoch 7/10\n",
            " - 7s - loss: 0.1426 - acc: 0.9667 - val_loss: 0.1492 - val_acc: 0.9667\n",
            "\n",
            "Epoch 8/10\n",
            " - 7s - loss: 0.1420 - acc: 0.9667 - val_loss: 0.1489 - val_acc: 0.9667\n",
            "\n",
            "Epoch 9/10\n",
            " - 7s - loss: 0.1417 - acc: 0.9666 - val_loss: 0.1477 - val_acc: 0.9667\n",
            "\n",
            "Epoch 10/10\n",
            " - 7s - loss: 0.1406 - acc: 0.9667 - val_loss: 0.1491 - val_acc: 0.9667\n",
            "\n",
            "Test accuracy:\n",
            "0.9666666388511658\n",
            " 70%|███████   | 7/10 [08:55<03:46, 75.60s/it, best loss: -0.9666666388511658]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/temp_model.py:173: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 6811 samples, validate on 6811 samples\n",
            "Epoch 1/10\n",
            " - 11s - loss: 0.1490 - acc: 0.9666 - val_loss: 0.1464 - val_acc: 0.9667\n",
            "\n",
            "Epoch 2/10\n",
            " - 7s - loss: 0.1486 - acc: 0.9667 - val_loss: 0.1464 - val_acc: 0.9667\n",
            "\n",
            "Epoch 3/10\n",
            " - 7s - loss: 0.1483 - acc: 0.9667 - val_loss: 0.1463 - val_acc: 0.9667\n",
            "\n",
            "Epoch 4/10\n",
            " - 7s - loss: 0.1482 - acc: 0.9667 - val_loss: 0.1463 - val_acc: 0.9667\n",
            "\n",
            "Epoch 5/10\n",
            " - 7s - loss: 0.1480 - acc: 0.9667 - val_loss: 0.1463 - val_acc: 0.9667\n",
            "\n",
            "Epoch 6/10\n",
            " - 7s - loss: 0.1478 - acc: 0.9667 - val_loss: 0.1463 - val_acc: 0.9667\n",
            "\n",
            "Epoch 7/10\n",
            " - 7s - loss: 0.1477 - acc: 0.9667 - val_loss: 0.1463 - val_acc: 0.9667\n",
            "\n",
            "Epoch 8/10\n",
            " - 7s - loss: 0.1476 - acc: 0.9667 - val_loss: 0.1463 - val_acc: 0.9667\n",
            "\n",
            "Epoch 9/10\n",
            " - 7s - loss: 0.1474 - acc: 0.9667 - val_loss: 0.1463 - val_acc: 0.9667\n",
            "\n",
            "Epoch 10/10\n",
            " - 7s - loss: 0.1473 - acc: 0.9667 - val_loss: 0.1463 - val_acc: 0.9667\n",
            "\n",
            "Test accuracy:\n",
            "0.9666666388511658\n",
            " 80%|████████  | 8/10 [10:09<02:30, 75.35s/it, best loss: -0.9666666388511658]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/temp_model.py:173: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 6811 samples, validate on 6811 samples\n",
            "Epoch 1/10\n",
            " - 11s - loss: 0.1465 - acc: 0.9666 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 2/10\n",
            " - 7s - loss: 0.1463 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 3/10\n",
            " - 7s - loss: 0.1461 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 4/10\n",
            " - 7s - loss: 0.1461 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 5/10\n",
            " - 7s - loss: 0.1462 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 6/10\n",
            " - 7s - loss: 0.1461 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 7/10\n",
            " - 7s - loss: 0.1461 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 8/10\n",
            " - 7s - loss: 0.1461 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 9/10\n",
            " - 7s - loss: 0.1461 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Epoch 10/10\n",
            " - 7s - loss: 0.1461 - acc: 0.9667 - val_loss: 0.1461 - val_acc: 0.9667\n",
            "\n",
            "Test accuracy:\n",
            "0.9666666388511658\n",
            " 90%|█████████ | 9/10 [11:25<01:15, 75.57s/it, best loss: -0.9666666388511658]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/temp_model.py:173: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 6811 samples, validate on 6811 samples\n",
            "Epoch 1/10\n",
            " - 12s - loss: 0.1451 - acc: 0.9667 - val_loss: 0.1477 - val_acc: 0.9667\n",
            "\n",
            "Epoch 2/10\n",
            " - 7s - loss: 0.1429 - acc: 0.9667 - val_loss: 0.1489 - val_acc: 0.9667\n",
            "\n",
            "Epoch 3/10\n",
            " - 7s - loss: 0.1418 - acc: 0.9667 - val_loss: 0.1492 - val_acc: 0.9667\n",
            "\n",
            "Epoch 4/10\n",
            " - 7s - loss: 0.1409 - acc: 0.9666 - val_loss: 0.1497 - val_acc: 0.9667\n",
            "\n",
            "Epoch 5/10\n",
            " - 7s - loss: 0.1402 - acc: 0.9667 - val_loss: 0.1503 - val_acc: 0.9667\n",
            "\n",
            "Epoch 6/10\n",
            " - 7s - loss: 0.1401 - acc: 0.9667 - val_loss: 0.1494 - val_acc: 0.9667\n",
            "\n",
            "Epoch 7/10\n",
            " - 7s - loss: 0.1394 - acc: 0.9667 - val_loss: 0.1552 - val_acc: 0.9667\n",
            "\n",
            "Epoch 8/10\n",
            " - 7s - loss: 0.1384 - acc: 0.9667 - val_loss: 0.1520 - val_acc: 0.9667\n",
            "\n",
            "Epoch 9/10\n",
            " - 7s - loss: 0.1379 - acc: 0.9667 - val_loss: 0.1589 - val_acc: 0.9667\n",
            "\n",
            "Epoch 10/10\n",
            " - 7s - loss: 0.1371 - acc: 0.9667 - val_loss: 0.1585 - val_acc: 0.9667\n",
            "\n",
            "Test accuracy:\n",
            "0.9666666388511658\n",
            "100%|██████████| 10/10 [12:48<00:00, 77.69s/it, best loss: -0.9666666388511658]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvMAj8UbNBXa",
        "colab_type": "code",
        "outputId": "3af2b4f1-cc14-41a2-c8a4-1a6b4d85a608",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "best_run"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Dense': 2,\n",
              " 'Dense_1': 2,\n",
              " 'Dropout': 0.6108763092812357,\n",
              " 'Dropout_1': 0.7371698374615214,\n",
              " 'Dropout_2': 0.6517968154887782,\n",
              " 'batch_size': 1,\n",
              " 'optimizer': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcRn1De9HVfQ",
        "colab_type": "code",
        "outputId": "c89afdae-6552-4c00-fe5f-1dc7f3ce1411",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(best_model.history.history['acc'])\n",
        "plt.plot(best_model.history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(best_model.history.history['loss'])\n",
        "plt.plot(best_model.history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEWCAYAAAC5XZqEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaKwU6ZRHb38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "os.mkdir('/content/drive/My Drive/Speech1/Models')\n",
        "filename = '/content/drive/My Drive/Speech1/Models/CNN_1D_model.sav'\n",
        "pickle.dump(best_model, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfVmqaPTIBOP",
        "colab_type": "code",
        "outputId": "785b431b-81d8-45b9-b798-69acc7edeebd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "best_run2d, best_model2d = optim.minimize(model=conv_2d_model,\n",
        "                                          data=data_2d,\n",
        "                                          max_evals=10,\n",
        "                                          algo=tpe.suggest,\n",
        "                                          notebook_name='parameteroptimization1', # This is important!\n",
        "                                          trials=Trials())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Imports:\n",
            "#coding=utf-8\n",
            "\n",
            "from __future__ import print_function\n",
            "\n",
            "try:\n",
            "    import numpy as np\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperopt import Trials, STATUS_OK, tpe\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.datasets import mnist\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers.core import Dense, Dropout, Activation\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.models import Sequential\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.utils import np_utils\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.models import Sequential\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.utils import to_categorical\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras import losses, models, optimizers\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, Activation, GaussianNoise, BatchNormalization, LeakyReLU, AveragePooling2D\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras import regularizers, optimizers\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.activations import relu, softmax\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Input, GlobalMaxPool1D, MaxPool1D\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from keras.layers import Convolution1D\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas import optim\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas.distributions import choice, uniform\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import os\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.model_selection import train_test_split\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import drive\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from pydrive.auth import GoogleAuth\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from pydrive.drive import GoogleDrive\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import auth\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from oauth2client.client import GoogleCredentials\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from shutil import copyfile\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import matplotlib.pyplot as plt\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import pickle\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import matplotlib.pyplot as plt\n",
            "except:\n",
            "    pass\n",
            "\n",
            ">>> Hyperas search space:\n",
            "\n",
            "def get_space():\n",
            "    return {\n",
            "        'Conv2D': hp.choice('Conv2D', [64, 128, 256]),\n",
            "        'kernel_size': hp.choice('kernel_size', [2, 3, 5]),\n",
            "        'Conv2D_1': hp.choice('Conv2D_1', [32, 64, 128]),\n",
            "        'Conv2D_2': hp.choice('Conv2D_2', [16, 32, 64]),\n",
            "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n",
            "        'batch_size': hp.choice('batch_size', [64, 128]),\n",
            "    }\n",
            "\n",
            ">>> Data\n",
            "  1: \n",
            "  2: X_train = np.load('NM_train.npy')\n",
            "  3: Y_train = np.load('NMy_train1.npy')\n",
            "  4: X_test = np.load('NM_test.npy')\n",
            "  5: Y_test = np.load('NMy_test1.npy')\n",
            "  6: X_test = X_test[0:5450]\n",
            "  7: Y_test = Y_test[0:5450]\n",
            "  8: \n",
            "  9: \n",
            " 10: \n",
            ">>> Resulting replaced keras model:\n",
            "\n",
            "   1: def keras_fmin_fnct(space):\n",
            "   2: \n",
            "   3: \n",
            "   4:     model = Sequential()\n",
            "   5:     #add model layers\n",
            "   6:     model.add(Conv2D(space['Conv2D'], kernel_size=space['kernel_size'], activation='relu', input_shape=(128 ,87,1)))\n",
            "   7:     model.add(BatchNormalization())\n",
            "   8:     model.add(Conv2D(space['Conv2D_1'], kernel_size=3, activation= 'relu'))\n",
            "   9:     model.add(BatchNormalization())\n",
            "  10:     model.add(Conv2D(space['Conv2D_2'], kernel_size=3, activation= 'relu'))\n",
            "  11:     model.add(BatchNormalization())\n",
            "  12:     model.add(Flatten())\n",
            "  13:     model.add(Dense(30, activation='softmax'))\n",
            "  14: \n",
            "  15:     #compile model using accuracy to measure model performance\n",
            "  16: \n",
            "  17:     model.compile(loss='binary_crossentropy',\n",
            "  18:                   optimizer=space['optimizer'],\n",
            "  19:                   metrics=['accuracy'])\n",
            "  20: \n",
            "  21:     model.fit(X_train, Y_train,\n",
            "  22:               batch_size=space['batch_size'],\n",
            "  23:               nb_epoch=10,\n",
            "  24:               verbose=2,\n",
            "  25:               validation_data=(X_test, Y_test))\n",
            "  26:     score, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
            "  27:     print('Test accuracy:', acc)\n",
            "  28:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
            "  29: \n",
            "  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/temp_model.py:173: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 8173 samples, validate on 5450 samples\n",
            "Epoch 1/10\n",
            " - 69s - loss: 0.9395 - acc: 0.9374 - val_loss: 1.0324 - val_acc: 0.9356\n",
            "\n",
            "Epoch 2/10\n",
            " - 62s - loss: 0.6757 - acc: 0.9455 - val_loss: 0.1348 - val_acc: 0.9656\n",
            "\n",
            "Epoch 3/10\n",
            " - 62s - loss: 0.0900 - acc: 0.9738 - val_loss: 0.1029 - val_acc: 0.9697\n",
            "\n",
            "Epoch 4/10\n",
            " - 62s - loss: 0.0247 - acc: 0.9932 - val_loss: 0.0942 - val_acc: 0.9714\n",
            "\n",
            "Epoch 5/10\n",
            " - 62s - loss: 0.0066 - acc: 0.9991 - val_loss: 0.0913 - val_acc: 0.9719\n",
            "\n",
            "Epoch 6/10\n",
            " - 62s - loss: 0.0029 - acc: 0.9999 - val_loss: 0.0904 - val_acc: 0.9724\n",
            "\n",
            "Epoch 7/10\n",
            " - 62s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0898 - val_acc: 0.9725\n",
            "\n",
            "Epoch 8/10\n",
            " - 62s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0894 - val_acc: 0.9727\n",
            "\n",
            "Epoch 9/10\n",
            " - 62s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0891 - val_acc: 0.9728\n",
            "\n",
            "Epoch 10/10\n",
            " - 62s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0889 - val_acc: 0.9728\n",
            "\n",
            "Test accuracy:\n",
            "0.9728379345596383\n",
            " 10%|█         | 1/10 [10:43<1:36:29, 643.30s/it, best loss: -0.9728379345596383]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/temp_model.py:173: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 8173 samples, validate on 5450 samples\n",
            "Epoch 1/10\n",
            " - 79s - loss: 0.9937 - acc: 0.9362 - val_loss: 0.9829 - val_acc: 0.9357\n",
            "\n",
            "Epoch 2/10\n",
            " - 67s - loss: 1.0095 - acc: 0.9355 - val_loss: 1.0188 - val_acc: 0.9356\n",
            "\n",
            "Epoch 3/10\n",
            " - 67s - loss: 1.0105 - acc: 0.9359 - val_loss: 1.0309 - val_acc: 0.9357\n",
            "\n",
            "Epoch 4/10\n",
            " - 67s - loss: 1.0228 - acc: 0.9356 - val_loss: 1.0045 - val_acc: 0.9355\n",
            "\n",
            "Epoch 5/10\n",
            " - 67s - loss: 1.0196 - acc: 0.9357 - val_loss: 1.0174 - val_acc: 0.9360\n",
            "\n",
            "Epoch 6/10\n",
            " - 67s - loss: 1.0199 - acc: 0.9357 - val_loss: 1.0207 - val_acc: 0.9358\n",
            "\n",
            "Epoch 7/10\n",
            " - 67s - loss: 1.0160 - acc: 0.9357 - val_loss: 1.0177 - val_acc: 0.9359\n",
            "\n",
            "Epoch 8/10\n",
            " - 67s - loss: 1.0007 - acc: 0.9360 - val_loss: 0.9923 - val_acc: 0.9359\n",
            "\n",
            "Epoch 9/10\n",
            " - 67s - loss: 0.9889 - acc: 0.9360 - val_loss: 0.9716 - val_acc: 0.9360\n",
            "\n",
            "Epoch 10/10\n",
            " - 67s - loss: 0.9726 - acc: 0.9366 - val_loss: 0.9854 - val_acc: 0.9368\n",
            "\n",
            "Test accuracy:\n",
            "0.9368073571493867\n",
            " 20%|██        | 2/10 [22:24<1:28:04, 660.53s/it, best loss: -0.9728379345596383]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/temp_model.py:173: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 8173 samples, validate on 5450 samples\n",
            "Epoch 1/10\n",
            " - 81s - loss: 0.9992 - acc: 0.9358 - val_loss: 1.0296 - val_acc: 0.9358\n",
            "\n",
            "Epoch 2/10\n",
            " - 74s - loss: 1.0339 - acc: 0.9355 - val_loss: 1.0271 - val_acc: 0.9355\n",
            "\n",
            "Epoch 3/10\n",
            " - 74s - loss: 1.0342 - acc: 0.9355 - val_loss: 1.0296 - val_acc: 0.9358\n",
            "\n",
            "Epoch 4/10\n",
            " - 74s - loss: 1.0299 - acc: 0.9355 - val_loss: 1.0318 - val_acc: 0.9356\n",
            "\n",
            "Epoch 5/10\n",
            " - 74s - loss: 1.0347 - acc: 0.9355 - val_loss: 1.0318 - val_acc: 0.9356\n",
            "\n",
            "Epoch 6/10\n",
            " - 74s - loss: 1.0347 - acc: 0.9355 - val_loss: 1.0318 - val_acc: 0.9356\n",
            "\n",
            "Epoch 7/10\n",
            " - 74s - loss: 1.0347 - acc: 0.9355 - val_loss: 1.0318 - val_acc: 0.9356\n",
            "\n",
            "Epoch 8/10\n",
            " - 74s - loss: 1.0347 - acc: 0.9355 - val_loss: 1.0318 - val_acc: 0.9356\n",
            "\n",
            "Epoch 9/10\n",
            " - 74s - loss: 1.0347 - acc: 0.9355 - val_loss: 1.0318 - val_acc: 0.9356\n",
            "\n",
            "Epoch 10/10\n",
            " - 74s - loss: 1.0347 - acc: 0.9355 - val_loss: 1.0318 - val_acc: 0.9356\n",
            "\n",
            "Test accuracy:\n",
            "0.9356330431929422\n",
            " 30%|███       | 3/10 [35:05<1:20:36, 690.88s/it, best loss: -0.9728379345596383]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/temp_model.py:173: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 8173 samples, validate on 5450 samples\n",
            "Epoch 1/10\n",
            " - 63s - loss: 0.9849 - acc: 0.9361 - val_loss: 1.0371 - val_acc: 0.9353\n",
            "\n",
            "Epoch 2/10\n",
            " - 53s - loss: 1.0306 - acc: 0.9357 - val_loss: 1.0371 - val_acc: 0.9353\n",
            "\n",
            "Epoch 3/10\n",
            " - 53s - loss: 1.0306 - acc: 0.9357 - val_loss: 1.0371 - val_acc: 0.9353\n",
            "\n",
            "Epoch 4/10\n",
            " - 53s - loss: 1.0306 - acc: 0.9357 - val_loss: 1.0371 - val_acc: 0.9353\n",
            "\n",
            "Epoch 5/10\n",
            " - 53s - loss: 1.0306 - acc: 0.9357 - val_loss: 1.0371 - val_acc: 0.9353\n",
            "\n",
            "Epoch 6/10\n",
            " - 53s - loss: 1.0306 - acc: 0.9357 - val_loss: 1.0371 - val_acc: 0.9353\n",
            "\n",
            "Epoch 7/10\n",
            " - 53s - loss: 1.0306 - acc: 0.9357 - val_loss: 1.0371 - val_acc: 0.9353\n",
            "\n",
            "Epoch 8/10\n",
            " - 53s - loss: 1.0306 - acc: 0.9357 - val_loss: 1.0371 - val_acc: 0.9353\n",
            "\n",
            "Epoch 9/10\n",
            " - 53s - loss: 1.0306 - acc: 0.9357 - val_loss: 1.0371 - val_acc: 0.9353\n",
            "\n",
            "Epoch 10/10\n",
            " - 53s - loss: 1.0306 - acc: 0.9357 - val_loss: 1.0371 - val_acc: 0.9353\n",
            "\n",
            "Test accuracy:\n",
            "0.9353027681035733\n",
            " 40%|████      | 4/10 [44:19<1:04:59, 649.85s/it, best loss: -0.9728379345596383]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/temp_model.py:173: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 8173 samples, validate on 5450 samples\n",
            "Epoch 1/10\n",
            " - 105s - loss: 1.0180 - acc: 0.9360 - val_loss: 1.0374 - val_acc: 0.9353\n",
            "\n",
            "Epoch 2/10\n",
            " - 94s - loss: 1.0311 - acc: 0.9355 - val_loss: 1.0295 - val_acc: 0.9356\n",
            "\n",
            "Epoch 3/10\n",
            " - 94s - loss: 1.0293 - acc: 0.9357 - val_loss: 1.0221 - val_acc: 0.9355\n",
            "\n",
            "Epoch 4/10\n",
            " - 93s - loss: 1.0325 - acc: 0.9356 - val_loss: 1.0348 - val_acc: 0.9354\n",
            "\n",
            "Epoch 5/10\n",
            " - 93s - loss: 1.0335 - acc: 0.9355 - val_loss: 1.0348 - val_acc: 0.9354\n",
            "\n",
            "Epoch 6/10\n",
            " - 93s - loss: 1.0336 - acc: 0.9355 - val_loss: 1.0348 - val_acc: 0.9354\n",
            "\n",
            "Epoch 7/10\n",
            " - 93s - loss: 1.0336 - acc: 0.9355 - val_loss: 1.0348 - val_acc: 0.9354\n",
            "\n",
            "Epoch 8/10\n",
            " - 93s - loss: 1.0336 - acc: 0.9355 - val_loss: 1.0348 - val_acc: 0.9354\n",
            "\n",
            "Epoch 9/10\n",
            " - 93s - loss: 1.0336 - acc: 0.9355 - val_loss: 1.0348 - val_acc: 0.9354\n",
            "\n",
            "Epoch 10/10\n",
            " - 93s - loss: 1.0336 - acc: 0.9355 - val_loss: 1.0348 - val_acc: 0.9354\n",
            "\n",
            "Test accuracy:\n",
            "0.9354495569981566\n",
            " 50%|█████     | 5/10 [1:00:24<1:02:01, 744.22s/it, best loss: -0.9728379345596383]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/temp_model.py:173: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 8173 samples, validate on 5450 samples\n",
            "Epoch 1/10\n",
            " - 54s - loss: 0.2111 - acc: 0.9616 - val_loss: 0.1755 - val_acc: 0.9658\n",
            "\n",
            "Epoch 2/10\n",
            " - 50s - loss: 0.1236 - acc: 0.9792 - val_loss: 0.1603 - val_acc: 0.9678\n",
            "\n",
            "Epoch 3/10\n",
            " - 50s - loss: 0.0790 - acc: 0.9906 - val_loss: 0.1254 - val_acc: 0.9699\n",
            "\n",
            "Epoch 4/10\n",
            " - 50s - loss: 0.0498 - acc: 0.9958 - val_loss: 0.1144 - val_acc: 0.9730\n",
            "\n",
            "Epoch 5/10\n",
            " - 50s - loss: 0.0447 - acc: 0.9972 - val_loss: 0.1132 - val_acc: 0.9732\n",
            "\n",
            "Epoch 6/10\n",
            " - 50s - loss: 0.0379 - acc: 0.9976 - val_loss: 0.0981 - val_acc: 0.9738\n",
            "\n",
            "Epoch 7/10\n",
            " - 50s - loss: 0.0246 - acc: 0.9983 - val_loss: 0.0977 - val_acc: 0.9740\n",
            "\n",
            "Epoch 8/10\n",
            " - 50s - loss: 0.0230 - acc: 0.9987 - val_loss: 0.0962 - val_acc: 0.9744\n",
            "\n",
            "Epoch 9/10\n",
            " - 50s - loss: 0.0225 - acc: 0.9987 - val_loss: 0.0956 - val_acc: 0.9747\n",
            "\n",
            "Epoch 10/10\n",
            " - 50s - loss: 0.0222 - acc: 0.9988 - val_loss: 0.0954 - val_acc: 0.9748\n",
            "\n",
            "Test accuracy:\n",
            "0.9748073542446172\n",
            " 60%|██████    | 6/10 [1:08:59<45:01, 675.46s/it, best loss: -0.9748073542446172]  "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/temp_model.py:173: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 8173 samples, validate on 5450 samples\n",
            "Epoch 1/10\n",
            " - 57s - loss: 1.0243 - acc: 0.9357 - val_loss: 1.0328 - val_acc: 0.9356\n",
            "\n",
            "Epoch 2/10\n",
            " - 53s - loss: 1.0313 - acc: 0.9357 - val_loss: 1.0326 - val_acc: 0.9356\n",
            "\n",
            "Epoch 3/10\n",
            " - 53s - loss: 1.0313 - acc: 0.9357 - val_loss: 1.0325 - val_acc: 0.9356\n",
            "\n",
            "Epoch 4/10\n",
            " - 53s - loss: 1.0309 - acc: 0.9357 - val_loss: 1.0328 - val_acc: 0.9356\n",
            "\n",
            "Epoch 5/10\n",
            " - 53s - loss: 1.0311 - acc: 0.9357 - val_loss: 1.0324 - val_acc: 0.9356\n",
            "\n",
            "Epoch 6/10\n",
            " - 53s - loss: 1.0307 - acc: 0.9357 - val_loss: 1.0328 - val_acc: 0.9356\n",
            "\n",
            "Epoch 7/10\n",
            " - 53s - loss: 1.0311 - acc: 0.9357 - val_loss: 1.0328 - val_acc: 0.9356\n",
            "\n",
            "Epoch 8/10\n",
            " - 53s - loss: 1.0313 - acc: 0.9357 - val_loss: 1.0328 - val_acc: 0.9356\n",
            "\n",
            "Epoch 9/10\n",
            " - 53s - loss: 1.0313 - acc: 0.9357 - val_loss: 1.0328 - val_acc: 0.9356\n",
            "\n",
            "Epoch 10/10\n",
            " - 53s - loss: 1.0313 - acc: 0.9357 - val_loss: 1.0328 - val_acc: 0.9356\n",
            "\n",
            "Test accuracy:\n",
            "0.9355718806905484\n",
            " 70%|███████   | 7/10 [1:18:08<31:52, 637.47s/it, best loss: -0.9748073542446172]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/temp_model.py:173: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 8173 samples, validate on 5450 samples\n",
            "Epoch 1/10\n",
            " - 143s - loss: 0.1376 - acc: 0.9663 - val_loss: 0.1178 - val_acc: 0.9679\n",
            "\n",
            "Epoch 2/10\n",
            " - 129s - loss: 0.0931 - acc: 0.9719 - val_loss: 0.1026 - val_acc: 0.9697\n",
            "\n",
            "Epoch 3/10\n",
            " - 129s - loss: 0.0713 - acc: 0.9774 - val_loss: 0.0933 - val_acc: 0.9714\n",
            "\n",
            "Epoch 4/10\n",
            " - 129s - loss: 0.0561 - acc: 0.9822 - val_loss: 0.0880 - val_acc: 0.9729\n",
            "\n",
            "Epoch 5/10\n",
            " - 129s - loss: 0.0443 - acc: 0.9864 - val_loss: 0.0868 - val_acc: 0.9731\n",
            "\n",
            "Epoch 6/10\n",
            " - 129s - loss: 0.0352 - acc: 0.9900 - val_loss: 0.0836 - val_acc: 0.9737\n",
            "\n",
            "Epoch 7/10\n",
            " - 129s - loss: 0.0279 - acc: 0.9929 - val_loss: 0.0820 - val_acc: 0.9742\n",
            "\n",
            "Epoch 8/10\n",
            " - 129s - loss: 0.0222 - acc: 0.9950 - val_loss: 0.0826 - val_acc: 0.9741\n",
            "\n",
            "Epoch 9/10\n",
            " - 129s - loss: 0.0178 - acc: 0.9964 - val_loss: 0.0812 - val_acc: 0.9742\n",
            "\n",
            "Epoch 10/10\n",
            " - 129s - loss: 0.0142 - acc: 0.9976 - val_loss: 0.0810 - val_acc: 0.9742\n",
            "\n",
            "Test accuracy:\n",
            "0.9742140797956275\n",
            " 80%|████████  | 8/10 [1:40:18<28:10, 845.32s/it, best loss: -0.9748073542446172]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/temp_model.py:173: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 8173 samples, validate on 5450 samples\n",
            "Epoch 1/10\n",
            " - 77s - loss: 1.0258 - acc: 0.9356 - val_loss: 1.0271 - val_acc: 0.9359\n",
            "\n",
            "Epoch 2/10\n",
            " - 71s - loss: 1.0315 - acc: 0.9354 - val_loss: 1.0102 - val_acc: 0.9360\n",
            "\n",
            "Epoch 3/10\n",
            " - 72s - loss: 1.0221 - acc: 0.9357 - val_loss: 1.0232 - val_acc: 0.9357\n",
            "\n",
            "Epoch 4/10\n",
            " - 72s - loss: 1.0254 - acc: 0.9356 - val_loss: 1.0211 - val_acc: 0.9358\n",
            "\n",
            "Epoch 5/10\n",
            " - 71s - loss: 1.0248 - acc: 0.9357 - val_loss: 1.0256 - val_acc: 0.9358\n",
            "\n",
            "Epoch 6/10\n",
            " - 71s - loss: 1.0296 - acc: 0.9357 - val_loss: 1.0249 - val_acc: 0.9360\n",
            "\n",
            "Epoch 7/10\n",
            " - 71s - loss: 1.0295 - acc: 0.9357 - val_loss: 1.0202 - val_acc: 0.9363\n",
            "\n",
            "Epoch 8/10\n",
            " - 71s - loss: 1.0228 - acc: 0.9361 - val_loss: 1.0214 - val_acc: 0.9361\n",
            "\n",
            "Epoch 9/10\n",
            " - 71s - loss: 1.0259 - acc: 0.9359 - val_loss: 1.0198 - val_acc: 0.9363\n",
            "\n",
            "Epoch 10/10\n",
            " - 71s - loss: 1.0260 - acc: 0.9359 - val_loss: 1.0188 - val_acc: 0.9364\n",
            "\n",
            "Test accuracy:\n",
            "0.9363547576676815\n",
            " 90%|█████████ | 9/10 [1:52:31<13:31, 811.54s/it, best loss: -0.9748073542446172]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/temp_model.py:173: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 8173 samples, validate on 5450 samples\n",
            "Epoch 1/10\n",
            " - 80s - loss: 0.9890 - acc: 0.9361 - val_loss: 1.0297 - val_acc: 0.9358\n",
            "\n",
            "Epoch 2/10\n",
            " - 71s - loss: 1.0336 - acc: 0.9355 - val_loss: 1.0297 - val_acc: 0.9358\n",
            "\n",
            "Epoch 3/10\n",
            " - 71s - loss: 1.0336 - acc: 0.9355 - val_loss: 1.0297 - val_acc: 0.9358\n",
            "\n",
            "Epoch 4/10\n",
            " - 71s - loss: 1.0336 - acc: 0.9355 - val_loss: 1.0297 - val_acc: 0.9358\n",
            "\n",
            "Epoch 5/10\n",
            " - 71s - loss: 1.0336 - acc: 0.9355 - val_loss: 1.0297 - val_acc: 0.9358\n",
            "\n",
            "Epoch 6/10\n",
            " - 71s - loss: 1.0336 - acc: 0.9355 - val_loss: 1.0297 - val_acc: 0.9358\n",
            "\n",
            "Epoch 7/10\n",
            " - 71s - loss: 1.0336 - acc: 0.9355 - val_loss: 1.0297 - val_acc: 0.9358\n",
            "\n",
            "Epoch 8/10\n",
            " - 71s - loss: 1.0336 - acc: 0.9355 - val_loss: 1.0297 - val_acc: 0.9358\n",
            "\n",
            "Epoch 9/10\n",
            " - 71s - loss: 1.0336 - acc: 0.9355 - val_loss: 1.0297 - val_acc: 0.9358\n",
            "\n",
            "Epoch 10/10\n",
            " - 71s - loss: 1.0336 - acc: 0.9355 - val_loss: 1.0297 - val_acc: 0.9358\n",
            "\n",
            "Test accuracy:\n",
            "0.9357676005144732\n",
            "100%|██████████| 10/10 [2:04:49<00:00, 789.56s/it, best loss: -0.9748073542446172]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiurzkQ8SWpP",
        "colab_type": "code",
        "outputId": "f5717338-cb2a-4256-cf8a-8b0173c7d2a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(best_model2d.history.history['acc'])\n",
        "plt.plot(best_model2d.history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(best_model2d.history.history['loss'])\n",
        "plt.plot(best_model2d.history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnHPONYsnEuecc83y/wFNqZ/4iFjBPQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nExQLEmOMMUGxIDHGGBMUCxJjjDFB+f+70bd/Tk8nXQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVwAZDiRX-Xq",
        "colab_type": "code",
        "outputId": "540053cf-220f-4407-bf17-fb3258ebbf04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "best_run2d"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Conv2D': 1,\n",
              " 'Conv2D_1': 0,\n",
              " 'Conv2D_2': 2,\n",
              " 'batch_size': 0,\n",
              " 'kernel_size': 2,\n",
              " 'optimizer': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg3j0IRcchES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "filename = '/content/drive/My Drive/Speech1/Models/CNN_2D_model.sav'\n",
        "pickle.dump(best_model2d, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOnkO1p8dIlE",
        "colab_type": "code",
        "outputId": "d1056dfb-a7db-4440-f66a-3c6a17e05ab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def solvethis(a,b):\n",
        "  return a+b\n",
        "\n",
        "s = solvethis(2,3)\n",
        "print(s)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U969QlXdBpFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}